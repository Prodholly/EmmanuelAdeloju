<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://prodholly.github.io/EmmanuelAdeloju/feed.xml" rel="self" type="application/atom+xml"/><link href="https://prodholly.github.io/EmmanuelAdeloju/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-02T00:01:16+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/feed.xml</id><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Frame the Problem</title><link href="https://prodholly.github.io/EmmanuelAdeloju/blog/2026/framing-the-problem/" rel="alternate" type="text/html" title="Frame the Problem"/><published>2026-02-01T00:00:00+00:00</published><updated>2026-02-01T00:00:00+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/blog/2026/framing-the-problem</id><content type="html" xml:base="https://prodholly.github.io/EmmanuelAdeloju/blog/2026/framing-the-problem/"><![CDATA[<h2 id="why-framing-the-problem-comes-first">Why Framing the Problem Comes First</h2> <p>Before we graph data, calculate averages, or run statistical tests, we need to step back and ask:</p> <p><strong>What problem are we actually trying to understand?</strong></p> <p>Framing the problem anchors a data investigation in real-world phenomena. According to Lee et al. (2022), effective data investigations do not begin with tools or techniques; they begin with context, purpose, and questions worth answering. This framing phase shapes every decision that follows, from the research question we pose to the data we choose to analyze.</p> <p>Importantly, this is not a one-time step. Throughout a data investigation, we return to the framing phase to ensure our analysis still aligns with the real-world problem we care about.</p> <hr/> <h2 id="learning-goals-for-this-module">Learning Goals for This Module</h2> <p>By the end of this module, teachers and students will be able to:</p> <ul> <li>Situate a data investigation in a real-world scientific context</li> <li>Move from broad issues → focused research questions</li> <li>Select or evaluate datasets that align with those questions</li> <li>Use LLMs productively to support (not replace) human sensemaking during framing</li> </ul> <hr/> <h2 id="step-1-identify-the-broader-issue-context-first">Step 1: Identify the Broader Issue (Context First)</h2> <p>Data investigations begin with real-world phenomena, not datasets.</p> <p>At this stage, I will ask you to zoom out and identify:</p> <ul> <li>What is happening in the world?</li> <li>Why does it matter?</li> <li>Who is affected?</li> </ul> <p>This is where background information comes in. We are not analyzing data yet; we are building contextual understanding.</p> <h3 id="example-electrical-fires-physical-science--engineering-context">Example: Electrical Fires (Physical Science / Engineering Context)</h3> <p>Suppose we want to investigate electrical fires.</p> <p>The broader issue might include:</p> <ul> <li>Repeated electrical fires in a community</li> <li>Power outages affecting homes and businesses</li> <li>Safety risks and economic consequences</li> </ul> <p>Here, the investigation is grounded in a real system that could be improved, which emphasizes problem-solving in context.</p> <h3 id="how-llms-may-support-this-step">How LLMs May Support This Step</h3> <p>LLMs are especially useful here for brainstorming and contextual exploration.</p> <p><strong>Example prompt (Zero-shot prompt):</strong></p> <blockquote> <p><em>“Act as a science teacher helping students understand a real-world problem.</em><br/> <em>What are some typical broader issues related to electrical fires in residential neighborhoods?”</em></p> </blockquote> <p>At this stage, the LLM helps surface possibilities, not answers. Teachers and students still decide which issues are relevant and meaningful in their context.</p> <hr/> <h2 id="step-2-clarify-why-the-problem-matters">Step 2: Clarify Why the Problem Matters</h2> <p>Once the broader issue is identified, the next step is to articulate why the investigation is important.</p> <p>This helps you move beyond “we have data” to “this data helps us understand something meaningful.”</p> <p>Questions that may be asked here include:</p> <ul> <li>What could change if we understood this problem better?</li> <li>What decisions might this data inform?</li> <li>How does this connect to science learning goals?</li> </ul> <h3 id="classroom-example">Classroom Example</h3> <p>In the electrical fire case:</p> <ul> <li>Understanding causes could inform safer building practices</li> <li>Data could help prioritize inspections or upgrades</li> <li>The investigation connects to concepts like conductivity, resistance, and materials science</li> </ul> <h3 id="using-llms-thoughtfully">Using LLMs Thoughtfully</h3> <p><strong>Example prompt (Zero-shot prompt):</strong></p> <blockquote> <p><em>“Why might understanding the causes of electrical fires be important for community safety and engineering decisions?”</em></p> </blockquote> <p>This supports sensemaking, but students should still discuss and refine the importance in their own words.</p> <hr/> <h2 id="step-3-develop-investigative-research-questions">Step 3: Develop Investigative (Research) Questions</h2> <p>Only after understanding the broader issue do we narrow our focus.</p> <p>Framing the problem includes determining what focus is most productive. Sometimes, the initial problem needs to be reframed into a question that is more answerable with available data.</p> <h3 id="from-broad-issue-to-research-question">From Broad Issue to Research Question</h3> <p><strong>Broad issue:</strong></p> <blockquote> <p><em>Electrical fires are increasing in residential areas.</em></p> </blockquote> <p><strong>Focused investigative question:</strong></p> <blockquote> <p><em>“What types of electrical wire materials are most commonly associated with electrical fire incidents?”</em></p> </blockquote> <p>This question:</p> <ul> <li>Is specific</li> <li>Can be answered using data</li> <li>Connects directly to scientific concepts (materials, conductivity, heat)</li> </ul> <h3 id="using-llms-to-refine-questions">Using LLMs to Refine Questions</h3> <p>LLMs are particularly useful for question refinement, not question generation alone.</p> <p><strong>Example prompt (Zero-shot prompt):</strong></p> <blockquote> <p><em>“Here is a broad issue: electrical fires in residential buildings.</em><br/> <em>Suggest three possible data-driven research questions that could be investigated using existing datasets.”</em></p> </blockquote> <p>Teachers and students then evaluate:</p> <ul> <li>Which question is measurable?</li> <li>Which aligns with the data we can access?</li> <li>Which best supports our learning goals?</li> </ul> <hr/> <h2 id="step-4-identify-and-evaluate-available-data">Step 4: Identify and Evaluate Available Data</h2> <p>Once a research question is defined, we ask:</p> <p><strong>What data would help us answer this question?</strong></p> <p>This includes:</p> <ul> <li>What variables are needed?</li> <li>What measurements matter?</li> <li>What limitations exist in the data?</li> </ul> <h3 id="example-continued">Example Continued</h3> <p><strong>Research question:</strong></p> <blockquote> <p><em>“What electrical wire materials are most commonly used in electrical fire incidents?”</em></p> </blockquote> <p>Possible datasets might include:</p> <ul> <li>Fire incident reports</li> <li>Building inspection records</li> <li>Material type and installation year</li> </ul> <p>Here, alignment matters. A dataset that lacks wire material information, even if large, is not useful for this question.</p> <h3 id="llms-as-data-selection-aids">LLMs as Data-Selection Aids</h3> <p><strong>Example prompt:</strong></p> <blockquote> <p><em>“Given this research question [paste research question here], what types of data variables would be necessary to investigate it?”</em></p> </blockquote> <p>The LLM helps identify what to look for, but teachers and students still evaluate data quality and relevance.</p> <hr/> <h2 id="step-5-revisiting-the-frame-iterative-sensemaking">Step 5: Revisiting the Frame (Iterative Sensemaking)</h2> <p>A key point from Lee et al. (2022) is that framing the problem is <strong>iterative</strong>.</p> <p>As data is explored, we may realize:</p> <ul> <li>The question is too broad</li> <li>The data is incomplete</li> <li>A different question is more productive</li> </ul> <p>At this point, we return to framing, not as failure, but as scientific practice.</p> <p><strong>Example Reflection Prompt (Zero-shot prompting):</strong></p> <blockquote> <p><em>“Based on the available data, does this research question need to be refined? If so, suggest how.”</em></p> </blockquote> <p>This models authentic data science and scientific inquiry.</p> <hr/> <h2 id="closing-the-module">Closing the Module</h2> <p>In this module, I want teachers and students to see that data investigation begins long before analysis. Framing the problem shapes the questions we ask, the data we select, and the conclusions we draw.</p> <p>LLMs are powerful partners in this phase, but only when used to expand thinking, not replace it.</p> <p>In the next module, we move from framing to exploring and preparing data, where numbers, variability, and patterns take center stage.</p> <hr/> <p><strong>Reference:</strong></p> <p>Lee, V. R., Wilkerson, M. H., &amp; Lanouette, K. (2022). A call for a reimagined science education data literacy. <em>Journal of Research in Science Teaching</em>, 59(6), 1019-1049.</p>]]></content><author><name>Emmanuel Adeloju</name></author><category term="data investigation"/><category term="problem framing"/><category term="science education"/><category term="data sensemaking"/><summary type="html"><![CDATA[Understanding how to anchor data investigations in real-world phenomena by framing problems before analysis begins.]]></summary></entry><entry><title type="html">Intro to Large Language Models</title><link href="https://prodholly.github.io/EmmanuelAdeloju/blog/2026/intro-to-llm/" rel="alternate" type="text/html" title="Intro to Large Language Models"/><published>2026-02-01T00:00:00+00:00</published><updated>2026-02-01T00:00:00+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/blog/2026/intro-to-llm</id><content type="html" xml:base="https://prodholly.github.io/EmmanuelAdeloju/blog/2026/intro-to-llm/"><![CDATA[<h2 id="why-this-module-matters">Why This Module Matters</h2> <p>Before asking teachers to use AI for data analysis and sensemaking, it is important to slow down and build a <strong>shared mental model</strong> of what Large Language Models (LLMs) actually are—and what they are not.</p> <p>This matters because how we understand these tools directly shapes:</p> <ul> <li>how we use them in instruction,</li> <li>how much we trust them, and</li> <li>how we design prompts for them.</li> </ul> <p>Without a clear mental model, it is easy to overestimate what LLMs can do or to misuse them in ways that undermine student sensemaking rather than support it.</p> <hr/> <h2 id="what-is-a-large-language-model-llm">What Is a Large Language Model (LLM)?</h2> <p>Large Language Models (LLMs) are a type of Artificial Intelligence (AI) designed to work with <strong>human language</strong>. They are trained on massive collections of text and learn <strong>statistical patterns in language</strong>, enabling them to generate new text that sounds coherent and contextually appropriate.</p> <p>In practical terms, LLMs can:</p> <ul> <li>respond to questions,</li> <li>summarize text,</li> <li>generate explanations,</li> <li>translate languages,</li> <li>write code, and</li> <li>support <em>language-based sensemaking</em> around data.</li> </ul> <p>Common examples include:</p> <ul> <li><strong>ChatGPT</strong> (OpenAI)</li> <li><strong>Claude</strong> (Anthropic)</li> <li><strong>Gemini</strong> (Google)</li> <li><strong>LLaMA</strong> (Meta)</li> </ul> <p>Most models teachers encounter are <strong>general-purpose models</strong>. This means they are designed to perform reasonably well across many tasks, rather than being experts in a single discipline such as statistics or data science.</p> <blockquote> <p><strong>Key takeaway:</strong><br/> LLMs are <em>language models</em>, not data analysis engines or reasoning agents.</p> </blockquote> <figure> <picture> <source class="responsive-img-srcset" srcset="/EmmanuelAdeloju/assets/img/prompt-480.webp 480w,/EmmanuelAdeloju/assets/img/prompt-800.webp 800w,/EmmanuelAdeloju/assets/img/prompt-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/EmmanuelAdeloju/assets/img/prompt.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">A simplified view of how a prompt guides a Large Language Model to generate a response by predicting likely next words rather than reasoning from data.</figcaption> </figure> <p>Fig 1. A simplified view of how a prompt guides a Large Language Model to generate a response by predicting likely next words rather than reasoning from data</p> <hr/> <h2 id="llms-are-pattern-based-not-reasoning-agents">LLMs Are Pattern-Based, Not Reasoning Agents</h2> <p>This is one of the most important ideas in this module.</p> <p>LLMs do not <em>understand</em> data, concepts, or scientific phenomena in the way humans do. Instead, they generate responses by predicting what words are most likely to come next based on patterns learned during training.</p> <p>When an LLM provides a convincing explanation of a graph or trend, it is <strong>not reasoning from first principles</strong>. It is drawing on patterns it has encountered in similar explanations across its training data.</p> <p>This is why LLM outputs can:</p> <ul> <li>sound confident even when incorrect,</li> <li>use appropriate scientific language without grounding claims in evidence, and</li> <li>miss contextual details that matter in classrooms.</li> </ul> <p>Understanding this limitation is essential for using LLMs productively in science education.</p> <hr/> <h2 id="how-do-llms-learn-a-teacher-friendly-overview">How Do LLMs Learn? (A Teacher-Friendly Overview)</h2> <p>Teachers do not need all the technical details—but they <em>do</em> need intuition. Understanding how these models are trained helps us interact with them more critically and productively.</p> <h3 id="training-at-a-high-level">Training at a High Level</h3> <p>LLMs are trained in three main stages.</p> <h3 id="stage-1-data-collection-and-preprocessing">Stage 1: Data Collection and Preprocessing</h3> <p>The model is first exposed to enormous amounts of text from sources such as:</p> <ul> <li>websites,</li> <li>Wikipedia,</li> <li>books,</li> <li>articles, and</li> <li>other publicly available text.</li> </ul> <p>This data is cleaned and filtered to remove low-quality or duplicate content. While this process is extensive, it is imperfect—meaning biases and gaps can remain.</p> <p><strong>Educational implication:</strong><br/> What the model “knows” depends entirely on what it has encountered in text form.</p> <h3 id="stage-2-pretraining-learning-language-patterns">Stage 2: Pretraining (Learning Language Patterns)</h3> <p>During pretraining, the model learns general patterns in language by predicting missing or next words across <strong>billions (or trillions) of words</strong>.</p> <p>For example, an earlier version of ChatGPT (GPT-3.5) was trained on approximately <strong>45 TB of compressed text before filtering</strong>, and about <strong>570 GB after filtering</strong> (Brown et al., 2020), representing hundreds of billions to trillions of words. Training on such broad and diverse text sources results in <strong>general-purpose models</strong> rather than deep expertise in any single discipline.</p> <p>For instance, if given the prompt:</p> <blockquote> <p><em>“When the temperature increases, the solubility of most solids in water…”</em></p> </blockquote> <p>The model learns that phrases like <em>“also increases”</em> are statistically likely to follow.</p> <p>This stage creates a model that can respond across many topics, but without disciplinary understanding.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/EmmanuelAdeloju/assets/img/llmprediction-480.webp 480w,/EmmanuelAdeloju/assets/img/llmprediction-800.webp 800w,/EmmanuelAdeloju/assets/img/llmprediction-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/EmmanuelAdeloju/assets/img/llmprediction.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Large Language Models generate responses by predicting the most probable next tokens based on patterns learned during training, not by reasoning from first principles.</figcaption> </figure> <h3 id="stage-3-fine-tuning-specialization">Stage 3: Fine-Tuning (Specialization)</h3> <p>After pretraining, models can be fine-tuned using smaller, more focused datasets or human feedback.</p> <p>Fine-tuning means adjusting a pretrained model so it performs better on specific types of tasks (e.g., education, coding, or scientific explanation). This process often relies on <strong>transfer learning</strong>—using general language knowledge as a foundation rather than learning from scratch.</p> <p><strong>Plain-language definition:</strong><br/> <em>Transfer learning</em> means starting with a broadly trained model and refining it for a specific purpose.</p> <p><strong>Educational implication:</strong><br/> Even “education-focused” AI tools still rely on general language patterns, not deep disciplinary understanding.</p> <hr/> <h2 id="prompting-and-prompt-engineering">Prompting and Prompt Engineering</h2> <h3 id="what-is-a-prompt">What Is a Prompt?</h3> <p>A prompt is the input we give an LLM—usually text—that describes:</p> <ul> <li>the task,</li> <li>the context, and</li> <li>the expected type of response.</li> </ul> <p><strong>Example prompt:</strong></p> <blockquote> <p><em>“Explain the trend shown in this graph to a 7th-grade student using evidence from the data.”</em></p> </blockquote> <h3 id="what-is-prompt-engineering">What Is Prompt Engineering?</h3> <p>Prompt engineering is the intentional design and refinement of prompts to:</p> <ul> <li>clarify the task,</li> <li>constrain the model’s response, and</li> <li>align outputs with instructional goals.</li> </ul> <p>In education, prompt engineering is less about “hacking” the model and more about <strong>pedagogical precision</strong>.</p> <p>I think of prompt engineering as <strong>lesson design for an AI collaborator</strong>.</p> <p>We will discuss Prompt Engineering more in Module 2.</p> <hr/> <h2 id="why-llms-can-be-helpful-for-science-data-sensemaking">Why LLMs Can Be Helpful for Science Data Sensemaking</h2> <p>Despite their limitations, LLMs can be powerful sensemaking supports when used carefully.</p> <p>They are especially useful for:</p> <ul> <li>translating data patterns into explanatory language,</li> <li>generating multiple interpretations of the same dataset,</li> <li>supporting claim–evidence–reasoning (CER),</li> <li>helping teachers anticipate student misconceptions.</li> </ul> <p>What they cannot do reliably is:</p> <ul> <li>validate conclusions,</li> <li>detect subtle data errors, or</li> <li>replace student reasoning or disciplinary judgment.</li> </ul> <hr/> <h2 id="major-risks-teachers-need-to-be-aware-of">Major Risks Teachers Need to Be Aware Of</h2> <p>To use LLMs responsibly, we need to be explicit about the risks.</p> <h3 id="attributing-human-like-reasoning">Attributing Human-Like Reasoning</h3> <p>Fluent language can easily be mistaken for genuine understanding. This may lead to overconfidence in explanations that are not grounded in the data.</p> <h3 id="uncritical-trust-in-outputs">Uncritical Trust in Outputs</h3> <p>Repeated “good enough” responses can create a false sense of reliability. Without verification, incorrect interpretations may go unnoticed.</p> <h3 id="invisible-influence-on-thinking">Invisible Influence on Thinking</h3> <p>LLMs do not just answer questions—they <strong>frame problems</strong>. Their suggestions can subtly shape how data is interpreted or narrow the range of explanations considered.</p> <h3 id="displacement-of-collaborative-sensemaking">Displacement of Collaborative Sensemaking</h3> <p>Over-reliance on AI can reduce opportunities for productive struggle, discussion, and collaborative reasoning, all of which are essential in science learning.</p> <h3 id="erosion-of-analytical-judgment">Erosion of Analytical Judgment</h3> <p>When teachers or students defer too often to AI-generated interpretations, their ability to independently evaluate evidence and detect errors may weaken over time.</p> <hr/> <h2 id="closing-reflection">Closing Reflection</h2> <p>The goal of this module is not to convince you that LLMs are good or bad. Rather, it is to help you see these tools clearly—as powerful language-based systems that can support science data sensemaking <strong>only when humans remain firmly in the loop</strong>.</p> <p>This understanding sets the foundation for the next module, where we move from <em>what LLMs are</em> to <em>how we design prompts</em> that support meaningful data analysis in classrooms.</p>]]></content><author><name>Emmanuel Adeloju</name></author><category term="LLMs"/><category term="AI literacy"/><category term="education"/><category term="data science"/><summary type="html"><![CDATA[Building a shared mental model of what Large Language Models actually are, and what they are not.]]></summary></entry><entry><title type="html">Prompt Engineering Framework for Data Sensemaking</title><link href="https://prodholly.github.io/EmmanuelAdeloju/blog/2026/prompt-framework/" rel="alternate" type="text/html" title="Prompt Engineering Framework for Data Sensemaking"/><published>2026-02-01T00:00:00+00:00</published><updated>2026-02-01T00:00:00+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/blog/2026/prompt-framework</id><content type="html" xml:base="https://prodholly.github.io/EmmanuelAdeloju/blog/2026/prompt-framework/"><![CDATA[<h2 id="what-is-data-sensemaking">What is Data Sensemaking?</h2> <p><strong>Data sensemaking</strong> is the process of engaging with data to explain, interpret, and understand a phenomenon, not just compute results.</p> <p>In science education, sensemaking involves connecting numerical patterns to underlying mechanisms, evidence, and uncertainty. It moves beyond simple calculation to ask:</p> <ul> <li>What does this pattern mean?</li> <li>Why might it occur?</li> <li>What are we still uncertain about?</li> </ul> <p>When working with LLMs, prompt engineering becomes the method by which we structure scientific thinking, guiding the model to reason with data in ways aligned with scientific inquiry.</p> <hr/> <h2 id="the-sense-framework-for-data-sensemaking-prompts">The SENSE Framework for Data Sensemaking Prompts</h2> <p>We introduce <strong>SENSE</strong>, a prompt engineering framework grounded in core practices of scientific investigation:</p> <p><strong>S</strong> — Specify the phenomenon<br/> <strong>E</strong> — Establish the data and variables<br/> <strong>N</strong> — Name the analytical task<br/> <strong>S</strong> — Support claims with evidence<br/> <strong>E</strong> — Examine limitations and uncertainty</p> <p>This framework helps teachers and students move from raw data to meaningful explanations that support understanding of phenomena of interest.</p> <hr/> <h2 id="1-specify-the-phenomenon">1. Specify the Phenomenon</h2> <p>Clearly state what real-world or scientific phenomenon the data represents.</p> <p>This anchors the model in <strong>meaning, not just numbers</strong>.</p> <p><strong>Example (Physics):</strong></p> <blockquote> <p><em>“The data represents how the period of a pendulum changes as string length increases.”</em></p> </blockquote> <p>By naming the phenomenon explicitly, you help the model connect calculations to real-world scientific concepts rather than treating the data as abstract numbers.</p> <hr/> <h2 id="2-establish-the-data-and-variables">2. Establish the Data and Variables</h2> <p>Explicitly describe:</p> <ul> <li>What each variable represents</li> <li>Units of measurement</li> <li>Sample size or conditions (if known)</li> </ul> <p>This prevents the model from inventing assumptions.</p> <p><strong>Example (Chemistry):</strong></p> <blockquote> <p><em>“The dataset includes temperature (°C) and reaction rate (mol/s) measured across five trials.”</em></p> </blockquote> <p>Providing this context ensures the model grounds its reasoning in the actual structure and constraints of your data.</p> <hr/> <h2 id="3-name-the-analytical-task">3. Name the Analytical Task</h2> <p>State exactly what kind of sensemaking is required, not just “analyze.”</p> <p><strong>Examples of tasks:</strong></p> <ul> <li>Identify patterns or trends</li> <li>Compare groups</li> <li>Quantify relationships</li> <li>Interpret variability</li> </ul> <p><strong>Example (Biology):</strong></p> <blockquote> <p><em>“Identify any relationship between light intensity and plant growth rate.”</em></p> </blockquote> <p>Being specific about the analytical task helps the model focus its reasoning on the appropriate type of pattern recognition or comparison.</p> <hr/> <h2 id="4-support-claims-with-evidence">4. Support Claims with Evidence</h2> <p>Require the model to tie every claim to the data, using numbers or comparisons.</p> <p>This mirrors <strong>scientific argumentation</strong>.</p> <p><strong>Example (Mathematics / Statistics):</strong></p> <blockquote> <p><em>“Use specific values or ranges from the dataset to support each claim you make.”</em></p> </blockquote> <p>This step ensures that explanations are grounded in evidence rather than general statements that could apply to any dataset.</p> <hr/> <h2 id="5-examine-limitations-and-uncertainty">5. Examine Limitations and Uncertainty</h2> <p>Prompt reflection on:</p> <ul> <li>Measurement error</li> <li>Sample size</li> <li>Missing variables</li> <li>Alternative explanations</li> </ul> <p>This step models <strong>scientific humility</strong>.</p> <p><strong>Example:</strong></p> <blockquote> <p><em>“Identify at least one limitation of the dataset that affects how confidently we can interpret the results.”</em></p> </blockquote> <p>By explicitly asking for limitations, you encourage critical thinking about the strength of conclusions and the boundaries of what the data can support.</p> <hr/> <h2 id="full-sense-prompt-example-integrated">Full SENSE Prompt Example (Integrated)</h2> <p><strong>Context:</strong> Middle school science — electrical resistance</p> <blockquote> <p><em>“The data represents measurements of electrical resistance (ohms) for wires of different lengths (meters). The dataset includes wire length and resistance values from one classroom experiment. Analyze the relationship between wire length and resistance. Use specific data values to support your explanation. Finally, identify one limitation of this dataset that affects the strength of your conclusion.”</em></p> </blockquote> <p><strong>Breaking down the SENSE components:</strong></p> <p><strong>S — Specify the phenomenon:</strong><br/> “measurements of electrical resistance (ohms) for wires of different lengths (meters)”</p> <p><strong>E — Establish the data and variables:</strong><br/> “wire length and resistance values from one classroom experiment”</p> <p><strong>N — Name the analytical task:</strong><br/> “Analyze the relationship between wire length and resistance”</p> <p><strong>S — Support claims with evidence:</strong><br/> “Use specific data values to support your explanation”</p> <p><strong>E — Examine limitations and uncertainty:</strong><br/> “identify one limitation of this dataset that affects the strength of your conclusion”</p> <p>This integrated prompt guides the LLM through a complete cycle of scientific reasoning, from phenomenon to evidence to critical reflection.</p> <hr/> <h2 id="moving-forward">Moving Forward</h2> <p>The SENSE framework provides a structured approach to prompt engineering that aligns with scientific thinking. By systematically incorporating these five elements, teachers can design prompts that support genuine data sensemaking rather than superficial pattern description.</p> <p>In practice, not every prompt needs all five elements—but being intentional about which elements to include helps ensure that LLM outputs support rather than replace scientific reasoning.</p>]]></content><author><name>Emmanuel Adeloju</name></author><category term="LLMs"/><category term="prompt engineering"/><category term="data sensemaking"/><category term="science education"/><category term="SENSE framework"/><summary type="html"><![CDATA[Introducing SENSE, a structured framework for designing prompts that support scientific data sensemaking with Large Language Models.]]></summary></entry><entry><title type="html">Prompting Techniques for Science Data Analysis and Sensemaking</title><link href="https://prodholly.github.io/EmmanuelAdeloju/blog/2026/prompt-techniques/" rel="alternate" type="text/html" title="Prompting Techniques for Science Data Analysis and Sensemaking"/><published>2026-02-01T00:00:00+00:00</published><updated>2026-02-01T00:00:00+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/blog/2026/prompt-techniques</id><content type="html" xml:base="https://prodholly.github.io/EmmanuelAdeloju/blog/2026/prompt-techniques/"><![CDATA[<h2 id="understanding-prompt-engineering">Understanding Prompt Engineering</h2> <p>Before we dive into specific techniques, let me briefly remind you of what prompt engineering is—from a slightly different angle that may deepen your understanding. Prompt engineering is the design of tasks in natural language to LLMs to produce desired outputs. An important note: these prompt engineering guidelines work across different LLM models and tools. Whether you’re using ChatGPT, Claude, Gemini, or another model, these principles remain consistent.</p> <hr/> <h2 id="components-of-a-prompt">Components of a Prompt</h2> <p>Before writing effective prompts, we need to understand their building blocks. Every well-designed prompt contains some combination of these components:</p> <p><strong>Instruction:</strong> An instruction or task you want the model to do</p> <p><strong>Context:</strong> Additional information you add to your instruction to make the model give better output</p> <p><strong>Input data:</strong> The question or task you are asking the model</p> <p><strong>Output indicator:</strong> How you want the output to be</p> <p>Understanding these components allows you to intentionally craft prompts that guide the model toward the kind of response you need.</p> <hr/> <h2 id="the-role-of-context-in-prompting">The Role of Context in Prompting</h2> <p>In prompt writing, <strong>context</strong> is the background information and framing you give the model so it knows how to approach a task, not just what calculation to perform.</p> <p>When you ask an LLM to calculate the mean of 5 numbers, the bare question might be:</p> <blockquote> <p><em>“What is the mean of these 5 numbers: 4, 7, 9, 10, 15?”</em></p> </blockquote> <p>Context is everything extra you add around that, such as:</p> <ul> <li>who the explanation is for,</li> <li>how detailed it should be, and</li> <li>what format to use.</li> </ul> <h3 id="example-without-much-context">Example Without Much Context</h3> <blockquote> <p><em>“Find the mean of these 5 numbers: 4, 7, 9, 10, 15.”</em></p> </blockquote> <p>The model knows it should compute the mean, but it doesn’t know:</p> <ul> <li>if it should show steps,</li> <li>explain the concept, or</li> <li>just output the final number.</li> </ul> <p>And even: mean of what numbers? Temperature or number of eggs?</p> <h3 id="example-with-richer-context">Example With Richer Context</h3> <blockquote> <p><em>“You are a friendly math tutor helping a 6th-grade student.</em> <em>Calculate the mean of the temperatures measured in five days: 4, 7, 9, 10, 15.</em> <em>First, show how to add the numbers, then divide by how many numbers there are, and finally give the answer in a full sentence the student can understand.”</em></p> </blockquote> <p>Here, the context includes:</p> <ul> <li><strong>Role:</strong> “friendly math tutor”</li> <li><strong>Audience:</strong> “6th-grade student”</li> <li><strong>Process:</strong> “show how to add,” then “divide by how many numbers,” then “give the answer in a full sentence”</li> </ul> <p>All of that shapes how the model performs the same core task: calculating the mean of 5 numbers.</p> <hr/> <h2 id="prompting-techniques-mapped-to-blooms-taxonomy">Prompting Techniques Mapped to Bloom’s Taxonomy</h2> <p>At this point, I assume we can agree that <strong>how we ask an LLM to work with data matters</strong>.</p> <p>So, let me introduce several prompting techniques and, more importantly, help you decide which technique fits which kind of data task.</p> <blockquote> <p><strong>Important note:</strong><br/> I do not recommend using all of these techniques all the time. Each technique is best suited for specific levels of task complexity, which I map explicitly to <strong>Bloom’s Taxonomy</strong> so teachers can make intentional choices.</p> </blockquote> <hr/> <h2 id="1-zero-shot-prompting">1. Zero-Shot Prompting</h2> <p><strong>Zero-shot prompting</strong> means asking the model to complete a task without providing any examples of how to do it.</p> <p>You give:</p> <ul> <li>The task</li> <li>The data</li> <li>Minimal framing</li> </ul> <h3 id="best-use-blooms-taxonomy">Best Use (Bloom’s Taxonomy)</h3> <ul> <li><strong>Remember</strong></li> <li><strong>Understand</strong></li> </ul> <p>This technique works best for simple, well-defined tasks where the goal is recall, identification, or basic interpretation.</p> <h3 id="physics-task-example">Physics Task Example</h3> <blockquote> <p><em>“What is a projectile?”</em></p> </blockquote> <p>This task is entirely about remembering and recalling. No need for any reasoning or evaluation.</p> <hr/> <h2 id="2-few-shot-prompting">2. Few-Shot Prompting</h2> <p><strong>Few-shot prompting</strong> provides one or more examples before asking the model to perform a new but similar task (Brown et al., 2020).</p> <p>This helps the model infer:</p> <ul> <li>The type of reasoning expected</li> <li>The structure of the response</li> </ul> <h3 id="best-use-blooms-taxonomy-1">Best Use (Bloom’s Taxonomy)</h3> <ul> <li><strong>Understand</strong></li> <li><strong>Apply</strong></li> </ul> <p>This technique is ideal for patterned data tasks or where students have to apply what they have learned to new forms of the same problem space.</p> <h3 id="chemistry-task-example">Chemistry Task Example</h3> <blockquote> <p><em>“Example:</em><br/> <em>Data: Temperature (°C): 10, 20, 30</em><br/> <em>Solubility (g): 15, 25, 35</em><br/> <em>Interpretation: As temperature increases, solubility increases.</em></p> <p><em>Now analyze this data:</em><br/> <em>Temperature (°C): 15, 12, 10</em><br/> <em>Solubility (g): 18, 12, 8</em><br/> <em>Describe the pattern.”</em></p> </blockquote> <p>The model sees the example and learns from that. Then mirrors the pattern to answer the new task.</p> <hr/> <h2 id="3-chain-of-thought-prompting">3. Chain-of-Thought Prompting</h2> <p><strong>Chain-of-thought prompting</strong> explicitly asks the model to show its (intermediate) reasoning steps (Wei et al., 2022).</p> <p>Use this sparingly and intentionally, especially when modeling reasoning.</p> <h3 id="best-use-blooms-taxonomy-2">Best Use (Bloom’s Taxonomy)</h3> <ul> <li><strong>Apply</strong></li> <li><strong>Analyze</strong></li> </ul> <p>This technique is best for multi-step data analysis, where the reasoning process matters as much as the answer.</p> <h3 id="biology-task-example">Biology Task Example</h3> <blockquote> <p><em>“A student measured heart rate (beats/min) before and after exercise:</em><br/> <em>Before: 72, 75, 73</em><br/> <em>After: 110, 115, 112</em><br/> <em>Calculate the mean for each condition and explain, step by step, what the data suggests about the effect of exercise.”</em></p> </blockquote> <p>In fact, there are two variations of chain-of-thought prompting:</p> <ul> <li><strong>Zero-shot CoT:</strong> Ask the model to reason step by step without providing examples.</li> <li><strong>Few-shot CoT:</strong> Provide a few step-by-step examples in the prompt to guide the model’s reasoning.</li> </ul> <hr/> <h2 id="4-self-consistency-prompting">4. Self-Consistency Prompting</h2> <p><strong>Self-consistency</strong> involves asking the model to generate multiple independent interpretations and then compare them (Wang et al., 2022).</p> <p>The goal is not agreement, but <strong>range and uncertainty</strong>.</p> <h3 id="best-use-blooms-taxonomy-3">Best Use (Bloom’s Taxonomy)</h3> <ul> <li><strong>Analyze</strong></li> <li><strong>Evaluate</strong></li> </ul> <p>This technique is especially useful for ambiguous or noisy data.</p> <h3 id="environmental-science-task-example">Environmental Science Task Example</h3> <blockquote> <p><em>“Based on this dataset showing CO₂ levels and temperature over time, generate three possible interpretations.</em><br/> <em>Then identify which interpretation is best supported by the data and explain why.”</em></p> </blockquote> <p>You may also paste the exact prompt into your LLM multiple times and compare the outputs and pick the majority answer. Your discretion is important here too—sometimes, the majority response will also be wrong.</p> <hr/> <h2 id="5-prompt-chaining">5. Prompt Chaining</h2> <p><strong>Prompt chaining</strong> breaks a complex task into a sequence of smaller prompts, where each output feeds into the next.</p> <p>This mirrors how we scaffold student thinking.</p> <h3 id="best-use-blooms-taxonomy-4">Best Use (Bloom’s Taxonomy)</h3> <ul> <li><strong>Apply</strong></li> <li><strong>Analyze</strong></li> <li><strong>Evaluate</strong></li> </ul> <p>This is ideal for extended data investigations.</p> <h3 id="science-data-example-mathematics--physics">Science Data Example (Mathematics / Physics)</h3> <p>In different prompts, do these:</p> <p><strong>Prompt 1:</strong></p> <blockquote> <p><em>“Calculate the mean velocity from this data.”</em></p> </blockquote> <p><strong>Prompt 2:</strong></p> <blockquote> <p><em>“Describe the trend shown in the velocity values.”</em></p> </blockquote> <p><strong>Prompt 3:</strong></p> <blockquote> <p><em>“Explain what this trend suggests about the motion.”</em></p> </blockquote> <hr/> <h2 id="moving-forward">Moving Forward</h2> <p>You now have a general understanding of how to prompt LLMs. We can then move on to how to construct prompts for data tasks, specifically.</p> <p>In the next module, we will apply these techniques to real science data analysis scenarios and explore how to design prompts that support authentic student sensemaking while maintaining scientific rigor.</p>]]></content><author><name>Emmanuel Adeloju</name></author><category term="LLMs"/><category term="prompt engineering"/><category term="data analysis"/><category term="science education"/><summary type="html"><![CDATA[A guide to choosing and applying the right prompting techniques for different levels of data tasks in science education.]]></summary></entry><entry><title type="html">a post with plotly.js</title><link href="https://prodholly.github.io/EmmanuelAdeloju/blog/2025/plotly/" rel="alternate" type="text/html" title="a post with plotly.js"/><published>2025-03-26T14:24:00+00:00</published><updated>2025-03-26T14:24:00+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/blog/2025/plotly</id><content type="html" xml:base="https://prodholly.github.io/EmmanuelAdeloju/blog/2025/plotly/"><![CDATA[<p>This is an example post with some <a href="https://plotly.com/javascript/">plotly</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}
</code></pre> <p>Also another example chart.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>This is how it looks like:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included plotly.js code could look like]]></summary></entry><entry><title type="html">a post with image galleries</title><link href="https://prodholly.github.io/EmmanuelAdeloju/blog/2024/photo-gallery/" rel="alternate" type="text/html" title="a post with image galleries"/><published>2024-12-04T01:59:00+00:00</published><updated>2024-12-04T01:59:00+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/blog/2024/photo-gallery</id><content type="html" xml:base="https://prodholly.github.io/EmmanuelAdeloju/blog/2024/photo-gallery/"><![CDATA[<p>The images in this post are all zoomable, arranged into different mini-galleries using different libraries.</p> <h2 id="lightbox2"><a href="https://lokeshdhakar.com/projects/lightbox2/">Lightbox2</a></h2> <p><a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p> <hr/> <h2 id="photoswipe"><a href="https://photoswipe.com/">PhotoSwipe</a></h2> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--getting-started"> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-pswp-width="1669" data-pswp-height="2500" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg" alt=""/> </a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-2500.jpg" data-pswp-width="1875" data-pswp-height="2500" data-cropped="true" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-200.jpg" alt=""/> </a> <a href="https://unsplash.com" data-pswp-src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1666" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg" alt=""/> </a> <div> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1667" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg" alt=""/> </a> </div> </div> <hr/> <h2 id="spotlight-js"><a href="https://nextapps-de.github.io/spotlight/">Spotlight JS</a></h2> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/> </a> </div> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg"/> </a> </div> <hr/> <h2 id="venobox"><a href="https://veno.es/venobox/">Venobox</a></h2> <p><a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what included image galleries could look like]]></summary></entry><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://prodholly.github.io/EmmanuelAdeloju/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://prodholly.github.io/EmmanuelAdeloju/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[<p>Learn more:Learn more:Learn more:Learn more:Learn more:Learn more:May 14, 2024 We’re introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants. In December, we launched our first natively multimodal model Gemini 1.0 in three sizes: Ultra, Pro and Nano. Just a few months later we released 1.5 Pro, with enhanced performance and a breakthrough long context window of 1 million tokens.Developers and enterprise customers have been putting 1.5 Pro to use in incredible ways and finding its long context window, multimodal reasoning capabilities and impressive overall performance incredibly useful.We know from user feedback that some applications need lower latency and a lower cost to serve. This inspired us to keep innovating, so today, we’re introducing Gemini 1.5 Flash: a model that’s lighter-weight than 1.5 Pro, and designed to be fast and efficient to serve at scale.Both 1.5 Pro and 1.5 Flash are available in public preview with a 1 million token context window in Google AI Studio and Vertex AI. And now, 1.5 Pro is also available with a 2 million token context window via waitlist to developers using the API and to Google Cloud customers.We’re also introducing updates across the Gemini family of models, announcing our next generation of open models, Gemma 2, and sharing progress on the future of AI assistants, with Project Astra.Context lengths of leading foundation models compared with Gemini 1.5’s 2 million token capability1.5 Flash is the newest addition to the Gemini model family and the fastest Gemini model served in the API. It’s optimized for high-volume, high-frequency tasks at scale, is more cost-efficient to serve and features our breakthrough long context window.While it’s a lighter weight model than 1.5 Pro, it’s highly capable of multimodal reasoning across vast amounts of information and delivers impressive quality for its size.The new Gemini 1.5 Flash model is optimized for speed and efficiency, is highly capable of multimodal reasoning and features our breakthrough long context window.1.5 Flash excels at summarization, chat applications, image and video captioning, data extraction from long documents and tables, and more. This is because it’s been trained by 1.5 Pro through a process called “distillation,” where the most essential knowledge and skills from a larger model are transferred to a smaller, more efficient model.Read more about 1.5 Flash in our updated Gemini 1.5 technical report, on the Gemini technology page, and learn about 1.5 Flash’s availability and pricing.Over the last few months, we’ve significantly improved 1.5 Pro, our best model for general performance across a wide range of tasks.Beyond extending its context window to 2 million tokens, we’ve enhanced its code generation, logical reasoning and planning, multi-turn conversation, and audio and image understanding through data and algorithmic advances. We see strong improvements on public and internal benchmarks for each of these tasks.1.5 Pro can now follow increasingly complex and nuanced instructions, including ones that specify product-level behavior involving role, format and style. We’ve improved control over the model’s responses for specific use cases, like crafting the persona and response style of a chat agent or automating workflows through multiple function calls. And we’ve enabled users to steer model behavior by setting system instructions.We added audio understanding in the Gemini API and Google AI Studio, so 1.5 Pro can now reason across image and audio for videos uploaded in Google AI Studio. And we’re now integrating 1.5 Pro into Google products, including Gemini Advanced and in Workspace apps.Read more about 1.5 Pro in our updated Gemini 1.5 technical report and on the Gemini technology page.Gemini Nano is expanding beyond text-only inputs to include images as well. Starting with Pixel, applications using Gemini Nano with Multimodality will be able to understand the world the way people do — not just through text, but also through sight, sound and spoken language.Read more about Gemini 1.0 Nano on Android.Today, we’re also sharing a series of updates to Gemma, our family of open models built from the same research and technology used to create the Gemini models.We’re announcing Gemma 2, our next generation of open models for responsible AI innovation. Gemma 2 has a new architecture designed for breakthrough performance and efficiency, and will be available in new sizes.The Gemma family is also expanding with PaliGemma, our first vision-language model inspired by PaLI-3. And we’ve upgraded our Responsible Generative AI Toolkit with LLM Comparator for evaluating the quality of model responses.Read more on the Developer blog.As part of Google DeepMind’s mission to build AI responsibly to benefit humanity, we’ve always wanted to develop universal AI agents that can be helpful in everyday life. That’s why today, we’re sharing our progress in building the future of AI assistants with Project Astra (advanced seeing and talking responsive agent).To be truly useful, an agent needs to understand and respond to the complex and dynamic world just like people do — and take in and remember what it sees and hears to understand context and take action. It also needs to be proactive, teachable and personal, so users can talk to it naturally and without lag or delay.While we’ve made incredible progress developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge. Over the past few years, we’ve been working to improve how our models perceive, reason and converse to make the pace and quality of interaction feel more natural.Building on Gemini, we’ve developed prototype agents that can process information faster by continuously encoding video frames, combining the video and speech input into a timeline of events, and caching this information for efficient recall.By leveraging our leading speech models, we also enhanced how they sound, giving the agents a wider range of intonations. These agents can better understand the context they’re being used in, and respond quickly, in conversation.With technology like this, it’s easy to envision a future where people could have an expert AI assistant by their side, through a phone or glasses. And some of these capabilities are coming to Google products, like the Gemini app and web experience, later this year.We’ve made incredible progress so far with our family of Gemini models, and we’re always striving to advance the state-of-the-art even further. By investing in a relentless production line of innovation, we’re able to explore new ideas at the frontier, while also unlocking the possibility of new and exciting Gemini use cases.Learn more about Gemini and its capabilities. Your information will be used in accordance with Google’s privacy policy.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Done. Just one step more.
    
      Check your inbox to confirm your subscription.
    You are already subscribed to our newsletter.
    You can also subscribe with a
    different email address
    
    .
    
  Let’s stay in touch. Get the latest news from Google in your inbox.
          Follow Us
</code></pre></div></div>]]></content><author><name></name></author><category term="external-posts"/><category term="google"/><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">a post with tabs</title><link href="https://prodholly.github.io/EmmanuelAdeloju/blog/2024/tabs/" rel="alternate" type="text/html" title="a post with tabs"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/blog/2024/tabs</id><content type="html" xml:base="https://prodholly.github.io/EmmanuelAdeloju/blog/2024/tabs/"><![CDATA[<p>This is how a post with <a href="https://github.com/Ovski4/jekyll-tabs">tabs</a> looks like. Note that the tabs could be used for different purposes, not only for code.</p> <h2 id="first-tabs">First tabs</h2> <p>To add tabs, use the following syntax:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">{%</span><span class="w"> </span><span class="nt">tabs</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-1</span><span class="w"> </span><span class="cp">%}</span>

Content 1

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-2</span><span class="w"> </span><span class="cp">%}</span>

Content 2

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtabs</span><span class="w"> </span><span class="cp">%}</span>
</code></pre></div></div> <p>With this you can generate visualizations like:</p> <ul id="log" class="tab" data-tab="efa91c94-9599-47b9-83fb-03359bdcfa41" data-name="log"> <li class="active" id="log-php"> <a href="#">php </a> </li> <li id="log-js"> <a href="#">js </a> </li> <li id="log-ruby"> <a href="#">ruby </a> </li> </ul> <ul class="tab-content" id="efa91c94-9599-47b9-83fb-03359bdcfa41" data-name="log"> <li class="active"> <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">var_dump</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello</span><span class="dl">"</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">pputs</span> <span class="dl">'</span><span class="s1">hello</span><span class="dl">'</span>
</code></pre></div></div> </li> </ul> <h2 id="another-example">Another example</h2> <ul id="data-struct" class="tab" data-tab="047b98a7-ce77-4b58-bde7-07ea44b95861" data-name="data-struct"> <li class="active" id="data-struct-yaml"> <a href="#">yaml </a> </li> <li id="data-struct-json"> <a href="#">json </a> </li> </ul> <ul class="tab-content" id="047b98a7-ce77-4b58-bde7-07ea44b95861" data-name="data-struct"> <li class="active"> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">hello</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">whatsup"</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">hi"</span>
</code></pre></div></div> </li> <li> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"hello"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"whatsup"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hi"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> </li> </ul> <h2 id="tabs-for-something-else">Tabs for something else</h2> <ul id="something-else" class="tab" data-tab="8b4ad3ff-4929-4dfc-a3f9-f33a04c1dda5" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="8b4ad3ff-4929-4dfc-a3f9-f33a04c1dda5" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included tabs in a post could look like]]></summary></entry><entry><title type="html">a post with typograms</title><link href="https://prodholly.github.io/EmmanuelAdeloju/blog/2024/typograms/" rel="alternate" type="text/html" title="a post with typograms"/><published>2024-04-29T23:36:10+00:00</published><updated>2024-04-29T23:36:10+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/blog/2024/typograms</id><content type="html" xml:base="https://prodholly.github.io/EmmanuelAdeloju/blog/2024/typograms/"><![CDATA[<p>This is an example post with some <a href="https://github.com/google/typograms/">typograms</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">+----+
|    |---&gt; My first diagram!
+----+</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-typograms">+----+
|    |---&gt; My first diagram!
+----+
</code></pre> <p>Another example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.</span>
<span class="p">```</span>
</code></pre></div></div> <p>which generates:</p> <pre><code class="language-typograms">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.
</code></pre> <p>For more examples, check out the <a href="https://google.github.io/typograms/#examples">typograms documentation</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included typograms code could look like]]></summary></entry><entry><title type="html">a post that can be cited</title><link href="https://prodholly.github.io/EmmanuelAdeloju/blog/2024/post-citation/" rel="alternate" type="text/html" title="a post that can be cited"/><published>2024-04-28T15:06:00+00:00</published><updated>2024-04-28T15:06:00+00:00</updated><id>https://prodholly.github.io/EmmanuelAdeloju/blog/2024/post-citation</id><content type="html" xml:base="https://prodholly.github.io/EmmanuelAdeloju/blog/2024/post-citation/"><![CDATA[<p>This is an example post that can be cited. The content of the post ends here, while the citation information is automatically provided below. The only thing needed is for you to set the <code class="language-plaintext highlighter-rouge">citation</code> key in the front matter to <code class="language-plaintext highlighter-rouge">true</code>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="citation"/><summary type="html"><![CDATA[this is what a post that can be cited looks like]]></summary></entry></feed>